<!DOCTYPE html>
<html lang="en">
<head>
<title>Image Editor</title>
<style id="css">
button, body, select, input {
	background-color: rgb(0, 0, 0);
}
button, body, a, p, h1, select, option, input {
	color: white;
}
</style>
</head>
<body>
Background Color: <input id="bgcolor" type="color">
<h1>Image Editor</h1>
<input id="image" type="file" accept=".jfif, .jpeg, .jpg, .png, .webp, .gif, .bmp, .svg, .cur, .avif, .ico, .apng, .tga"><br><a>File Treaty Type:</a><select id="treatimage"><option value="att">Attempt to decode the image data</option><option value="asa">Assume the file data is raw RGBA image data</option><option value="asb">Assume the file data is raw RGB image data</option><option value="asd">Assume the file data is raw grayscale image data</option><option value="asv">Attempt to decode the video data (and extract any frame selected)</option></select>
<hr>
<canvas id="canvas" width="300" height="300"></canvas>
<hr>
<select id="effects"><option>Please select an effect.</option><option value="restore">Restore Image</option><option value="tint">Tint (Filter Color)</option><option value="tintblend">Tint (Blend Color)</option><option value="shift">Shift</option><option value="backg">Apply Background</option><option value="gblur">Gaussian Blur</option><option value="crop">Crop</option><option value="inv">Invert Colors</option><option value="sharpg">High Contrast</option><option value="sepia">Sepia</option><option value="graya">Grayscale (By Average)</option><option value="grayb">Grayscale (By Brightness)</option><option value="grayc">Grayscale (By Color Channel)</option><option value="contr">Contrast</option><option value="flipx">Flip Horizontally</option><option value="flipy">Flip Vertically</option><option value="rgbsh">Shift RGB Colors To The Left</option><option value="rgbre">Reverse Order Of RGB Colors</option><option value="resi">Resize Image</option><option value="parag">Resize Image Without Aligning Columns</option><option value="resid">Resize Image Dimensions</option><option value="opac">Set Opacity</option><option value="jpeg">JPEG-ify</option><option value="webp">WEBP-ify</option><option value="minip">Minimize Color Palette</option><option value="jpegd">Image Distortion Animation</option><option value="rect">Draw Rectangle</option><option value="mp3">MP3-ify</option><option value="rotate">Rotate Left</option><option value="draw">Draw</option><option value="smudge">Smudge Right</option><option value="h264">H.264-ify</option></select><button id="apply">Apply Effect</button>
<div id="configs"></div>
<script>
// tga.js
const TYPE_NO_DATA=0,TYPE_INDEXED=1,TYPE_RGB=2,TYPE_GREY=3,TYPE_RLE_INDEXED=9,TYPE_RLE_RGB=10,TYPE_RLE_GREY=11,ORIGIN_BOTTOM_LEFT=0,ORIGIN_BOTTOM_RIGHT=1,ORIGIN_TOP_LEFT=2,ORIGIN_TOP_RIGHT=3,ORIGIN_SHIFT=4,ORIGIN_MASK=63;class TgaLoader{_checkHeader(){const e=this.header;if(0===e.imageType)throw new Error("No data");if(e.hasColorMap){if(e.colorMapLength>256||24!==e.colorMapDepth||1!==e.colorMapType)throw new Error("Invalid colormap for indexed type")}else if(e.colorMapType)throw new Error("Why does the image contain a palette?");if(!e.width||!e.height)throw new Error("Invalid image size");if(8!==e.pixelDepth&&16!==e.pixelDepth&&24!==e.pixelDepth&&32!==e.pixelDepth)throw new Error('Invalid pixel size "'+e.pixelDepth+'"')}_decodeRLE(e,t,a,r){const o=new Uint8Array(r),i=new Uint8Array(a);let h=0;for(;h<r;){const r=e[t++];let s=1+(127&r);if(128&r){for(let r=0;r<a;++r)i[r]=e[t+r];t+=a;for(let e=0;e<s;++e)o.set(i,h),h+=a}else{s*=a;for(let a=0;a<s;++a)o[h+a]=e[t+a];h+=s,t+=s}}return o}_getImageData8bits(e,t,a,r,o,i,h,s,l,g){for(let n=0,p=o;p!==h;p+=i)for(let o=s;o!==g;o+=l,n++){const i=t[n];e[4*(o+r*p)+3]=255,e[4*(o+r*p)+2]=a[3*i+0],e[4*(o+r*p)+1]=a[3*i+1],e[4*(o+r*p)+0]=a[3*i+2]}return e}_getImageData16bits(e,t,a,r,o,i,h,s,l,g){for(let a=0,n=o;n!==h;n+=i)for(let o=s;o!==g;o+=l,a+=2){const i=t[a+0]|t[a+1]<<8;e[4*(o+r*n)+0]=(31744&i)>>7,e[4*(o+r*n)+1]=(992&i)>>2,e[4*(o+r*n)+2]=(31&i)>>3,e[4*(o+r*n)+3]=32768&i?0:255}return e}_getImageData24bits(e,t,a,r,o,i,h,s,l,g){for(let a=0,n=o;n!==h;n+=i)for(let o=s;o!==g;o+=l,a+=3)e[4*(o+r*n)+3]=255,e[4*(o+r*n)+2]=t[a+0],e[4*(o+r*n)+1]=t[a+1],e[4*(o+r*n)]=t[a+2];return e}_getImageData32bits(e,t,a,r,o,i,h,s,l,g){for(let a=0,n=o;n!==h;n+=i)for(let o=s;o!==g;o+=l,a+=4)e[4*(o+r*n)+2]=t[a+0],e[4*(o+r*n)+1]=t[a+1],e[4*(o+r*n)]=t[a+2],e[4*(o+r*n)+3]=t[a+3];return e}_getImageDataGrey8bits(e,t,a,r,o,i,h,s,l,g){for(let a=0,n=o;n!==h;n+=i)for(let o=s;o!==g;o+=l,a++){const i=t[a];e[4*(o+r*n)+0]=i,e[4*(o+r*n)+1]=i,e[4*(o+r*n)+2]=i,e[4*(o+r*n)+3]=255}return e}_getImageDataGrey16bits(e,t,a,r,o,i,h,s,l,g){for(let a=0,n=o;n!==h;n+=i)for(let o=s;o!==g;o+=l,a+=2)e[4*(o+r*n)+0]=t[a+0],e[4*(o+r*n)+1]=t[a+0],e[4*(o+r*n)+2]=t[a+0],e[4*(o+r*n)+3]=t[a+1];return e}load(e){let t=0;if(e.length<18)throw new Error("Not enough data to contain header");const a={idLength:e[t++],colorMapType:e[t++],imageType:e[t++],colorMapIndex:e[t++]|e[t++]<<8,colorMapLength:e[t++]|e[t++]<<8,colorMapDepth:e[t++],offsetX:e[t++]|e[t++]<<8,offsetY:e[t++]|e[t++]<<8,width:e[t++]|e[t++]<<8,height:e[t++]|e[t++]<<8,pixelDepth:e[t++],flags:e[t++]};if(a.hasEncoding=9===a.imageType||10===a.imageType||11===a.imageType,a.hasColorMap=9===a.imageType||1===a.imageType,a.isGreyColor=11===a.imageType||3===a.imageType,this.header=a,this._checkHeader(),t+=a.idLength,t>=e.length)throw new Error("No data");if(a.hasColorMap){const r=a.colorMapLength*(a.colorMapDepth>>3);this.palette=e.subarray(t,t+r),t+=r}const r=a.pixelDepth>>3,o=a.width*a.height,i=o*r;a.hasEncoding?this.imageData=this._decodeRLE(e,t,r,i):this.imageData=e.subarray(t,t+(a.hasColorMap?o:i))}getImageData(e){const{width:t,height:a,flags:r,pixelDepth:o,isGreyColor:i}=this.header,h=(48&r)>>4;let s,l,g,n,p,c,d;switch(e||(e=document?document.createElement("canvas").getContext("2d").createImageData(t,a):{width:t,height:a,data:new Uint8ClampedArray(t*a*4)}),2===h||3===h?(n=0,p=1,c=a):(n=a-1,p=-1,c=-1),2===h||0===h?(s=0,l=1,g=t):(s=t-1,l=-1,g=-1),o){case 8:d=i?this._getImageDataGrey8bits:this._getImageData8bits;break;case 16:d=i?this._getImageDataGrey16bits:this._getImageData16bits;break;case 24:d=this._getImageData24bits;break;case 32:d=this._getImageData32bits}return d.call(this,e.data,this.imageData,this.palette,t,n,p,c,s,l,g),e}}

// custom H.264 library (written by AI. specifically, ChatGPT. then modified)
async function encodetoH264(imageData, callback, ps) {
	if (!window.VideoEncoder || !window.VideoFrame) {
		alert('WebCodecs is not supported in this browser. Try upgrading to a newer version, or switch to a different modern browser');
		return;
	}

	const videoEncoder = new VideoEncoder({
		output: (chunk) => callback(URL.createObjectURL(new Blob([chunk], "video/mp4"))),
		error: (e) => alert("Encoding error: " + e.message + ". Please send this issue in the GitHub repository: https://github.com/UnnamedBruh/newer-image-editor/")
	});

	const codecConfig = {
		codec: "h.264",
		width: imageData.width,
		height: imageData.height,
		framerate: 1,
		bitrate: Math.max(1000, Math.min(1000000, Math.round(+ps[0].value / 1000) * 1000))
	};

	try {
		videoEncoder.configure(codecConfig);
		const videoFrame = new VideoFrame(imageData, { timestamp: 0 });
		videoEncoder.encode(videoFrame);
		videoEncoder.close();
	} catch (err) {
		console.error("Error during encoding process: ", err);
	}
}

let isDrawing, lastX, lastY;

function loadTgaFromUint8Array(tgaData) {
	let buffer, image, loader;
	try {
		loader = new TgaLoader();
		loader.load(tgaData);
		console.log(tgaData);
		image = loader.imageData;
		console.log(image);
		console.log(loader.header);
		const possibleInstructions = [
			[
				(loader.header.flags & ORIGIN_MASK) === ORIGIN_BOTTOM_LEFT,
				"flip the image vertically."
			],
			[
				(loader.header.flags & ORIGIN_MASK) === ORIGIN_BOTTOM_RIGHT,
				"flip the image horizontally, and flip the image vertically."
			],
			[
				(loader.header.flags & ORIGIN_MASK) === ORIGIN_TOP_LEFT,
				"reverse the color channels' order, or shift the color channels' to the left repeatedly until the image's color feels right to you."
			],
			[
				(loader.header.flags & ORIGIN_MASK) === ORIGIN_TOP_RIGHT,
				"flip the image horizontally."
			]
		];
		let instructions = possibleInstructions.find(x => x[0])[1];
		alert("Proper handling for the TGA origins and different color orders should be handled manually. To get the original image, you must " + instructions + (instructions === "reverse the color channels' order, or shift the color channels' to the left repeatedly until the image's color feels right to you." ? "" : " You may also need to shift the color channels until the image's color feels right to you."));

		if (loader.header.pixelDepth === 24 || loader.header.colorMapDepth === 24) {
			const f = new Uint8ClampedArray(loader.header.width * loader.header.height * 4);
			const len = f.length;
			let index = 0, i = 0;
			for (; i < len; i++) {
				f[i] = image[index]; i++, index++;
				f[i] = image[index]; i++, index++;
				f[i] = image[index]; i++, index++;
				f[i] = 255;
			}
			return new ImageData(
				f,
				loader.header.width,
				loader.header.height
			);
		} else {
			return new ImageData(
				new Uint8ClampedArray(image),
				loader.header.width,
				loader.header.height
			);
		}
	} catch (err) {
		alert("There has been an error trying to decode the TGA image: " + err.message);
		if (tgaData.length === 0) alert("The TGA image contains no file data at all. This is needed to provide the context of the image (e.g. the width, height, color channels, etc), and the image data itself.");
		else if ((loader.header.pixelDepth === 24 && image.length !== loader.header.width * loader.header.height * 3) || (loader.header.pixelDepth === 32 && image.length !== loader.header.width * loader.header.height * 4)) alert("There appears to be an image data overflow (providing too many pixel values) or underflow (providing too little pixel values). This has to be fixed, so the image can correctly be loaded next time.");
		else if ([8, 16, 24, 32].indexOf(loader.header.pixelDepth) === -1) {
			if (confirm("The TGA image has a very odd specification of the pixel depth (provided was " + loader.header.pixelDepth + ", expected was 8, 16, 24, or 32). Do you want to provide the pixel depth?")) {
				//16
				let pixelDepth = +prompt("Provide the pixel depth (the default is 24).") || 24;
				if ([8, 16, 24, 32].indexOf(loader.header.pixelDepth) === -1) {
					while ([8, 16, 24, 32].indexOf(loader.header.pixelDepth) === -1) {
						alert("That level isn't recommended; you need to specify again.");
						pixelDepth = +prompt("Provide the pixel depth (the default is 24).") || 24;
					}
				}
				tgaData[16] = Math.round(pixelDepth & 256);
				loadTgaFromUint8Array(tgaData);
			}
		}
	}
}

const fileInput = document.getElementById("image"), treatFile = document.getElementById("treatimage"), canvas = document.getElementById("canvas"), effects = document.getElementById("effects"), applyEffect = document.getElementById("apply"), effectSettings = document.getElementById("configs");
const context = canvas.getContext("2d");
if (!context) {
	alert("Your browser does not support the 2D canvas context yet. Either upgrade to a newer version of your browser, or try using a different one.");
}
	let currentImageData = new ImageData(new Uint8ClampedArray(300 * 300 * 4), 300, 300), backupImageData = new ImageData(new Uint8ClampedArray(300 * 300 * 4), 300, 300), originalImage;
	fileInput.addEventListener("input", function(event) {
		const file = event.target.files[0];
		let fileReader = new FileReader();
		fileReader.onload = function(res) {
			if (treatFile.value === "att") {
				if (file.name.endsWith(".tga")) {
					alert("TGA.js is being used to decode the image. (Borrowed code from https://github.com/vthibault/tga.js/blob/master/src/tga.js - later modified to fit this editor's standards)");
					currentImageData = loadTgaFromUint8Array(new Uint8Array(res.target.result));
					backupImageData = new ImageData(new Uint8ClampedArray(currentImageData.data), currentImageData.width, currentImageData.height);
					canvas.width = currentImageData.width;
					canvas.height = currentImageData.height;
					context.clearRect(0, 0, +canvas.width, +canvas.height);
					context.putImageData(currentImageData, 0, 0);
				} else {
					const img = new Image();
					img.onload = function() {
						canvas.width = img.width;
						canvas.height = img.height;
						context.clearRect(0, 0, +canvas.width, +canvas.height);
						context.drawImage(img, 0, 0, +canvas.width, +canvas.height);
						currentImageData = context.getImageData(0, 0, +canvas.width, +canvas.height);
						backupImageData = new ImageData(new Uint8ClampedArray(currentImageData.data), currentImageData.width, currentImageData.height);
						originalImage = img;
					}
					img.src = res.target.result;
				}
			} else {
				if (treatFile.value !== "asv") {
					const width = Math.round(+(prompt("What should the width of the raw file data be for the final image? (The height is automatically determined. The default value is 300)") || 300));
					if (treatFile.value === "asa") {
						const height = Math.ceil(res.target.result.byteLength / width / 4);
						canvas.width = width;
						canvas.height = height;
						const roundedUint = new Uint8ClampedArray(width * height * 4);
						roundedUint.set(new Uint8ClampedArray(res.target.result));
						currentImageData = new ImageData(roundedUint, width, height);
						backupImageData = new ImageData(new Uint8ClampedArray(currentImageData.data), currentImageData.width, currentImageData.height);
						context.putImageData(currentImageData, 0, 0);
					} else if (treatFile.value === "asb") {
						const height = Math.ceil(res.target.result.byteLength / width / 3);
						canvas.width = width;
						canvas.height = height;
						const roundedUint = new Uint8ClampedArray(width * height * 4), buff = new Uint8ClampedArray(res.target.result);
						let byte = 0;
						for (let i = 0; i < roundedUint.byteLength;) {
							roundedUint[i] = buff[byte]; i++, byte++;
							roundedUint[i] = buff[byte]; i++, byte++;
							roundedUint[i] = buff[byte]; i++, byte++;
							roundedUint[i] = 255; i++;
						}
						currentImageData = new ImageData(roundedUint, width, height);
						backupImageData = new ImageData(new Uint8ClampedArray(currentImageData.data), currentImageData.width, currentImageData.height);
						context.putImageData(currentImageData, 0, 0);
					} else if (treatFile.value === "asd") {
						const height = Math.ceil(res.target.result.byteLength / width);
						canvas.width = width;
						canvas.height = height;
						const roundedUint = new Uint8ClampedArray(width * height * 4), buff = new Uint8ClampedArray(res.target.result);
						let first = 0;
						for (let i = 0; i < roundedUint.byteLength;) {
							roundedUint[i] = buff[first]; i++;
							roundedUint[i] = buff[first]; i++;
							roundedUint[i] = buff[first]; i++;
							roundedUint[i] = 255; i++; first++;
						}
						currentImageData = new ImageData(roundedUint, width, height);
						backupImageData = new ImageData(new Uint8ClampedArray(currentImageData.data), currentImageData.width, currentImageData.height);
						context.putImageData(currentImageData, 0, 0);
					}
				} else {
					fileInput.style.display = "none";
					const video = document.createElement("video");
					video.oncanplaythrough = function() {
						video.oncanplaythrough = function() {}
						setTimeout(function() {
							canvas.width = video.videoWidth;
							canvas.height = video.videoHeight;
							canvas.style.display = "none";
							context.clearRect(0, 0, +canvas.width, +canvas.height);
							document.body.appendChild(video);
							const bounding = video.getBoundingClientRect();
							if (canvas.width == 0 || canvas.height == 0) {
								canvas.width = bounding.width;
								canvas.height = bounding.height;
							}
							video.controls = true;
							const confirm = document.createElement("button");
							confirm.textContent = "Select Frame";
							document.body.appendChild(confirm);
							confirm.onclick = function() {
								video.pause();
								video.muted = true;
								confirm.onclick = function() {};
								setTimeout(function() {
									canvas.style.display = "";
									currentImageData = context.getImageData(0, 0, +canvas.width, +canvas.height);
									backupImageData = new ImageData(new Uint8ClampedArray(currentImageData.data), currentImageData.width, currentImageData.height);
									const image = new Image();
									image.src = canvas.toDataURL("image/png");
									originalImage = image;
									video.src = "";
									video.remove();
									fileInput.style.display = "";
									confirm.remove();
								}, 200);
							}
						}, 10);
					}
					video.src = res.target.result;
				}
			}
		}
		if ((treatFile.value === "att" || treatFile.value === "asv") && !file.name.endsWith(".tga")) fileReader.readAsDataURL(file); else fileReader.readAsArrayBuffer(file);
	});
	treatFile.oninput = function() {
		if (treatFile.value === "att") fileInput.accept = ".jfif, .jpeg, .jpg, .png, .webp, .gif, .bmp, .svg, .cur, .avif, .ico, .apng, .tga"; else if (treatFile.value === "asv") fileInput.accept = ".mp4, .ogg, .webm, .3gp"; else fileInput.accept = ".*";
	}
	let effectParams = [];
	function extractRGBA(hex, a) {
		const r = parseInt(hex.slice(1, 3), 16) / 255;
		const g = parseInt(hex.slice(3, 5), 16) / 255;
		const b = parseInt(hex.slice(5, 7), 16) / 255;
		return [r, g, b, a];
	}
	function extractRGBA2(hex, a) {
		const r = parseInt(hex.slice(1, 3), 16);
		const g = parseInt(hex.slice(3, 5), 16);
		const b = parseInt(hex.slice(5, 7), 16);
		return [r, g, b, a];
	}
	function interpolate(x, y, n) {
		return x + (y - x) * n;
	}
	function applyGaussianBlur(imageData, kernel) {
		const width = imageData.width;
		const height = imageData.height;
		const output = new ImageData(new Uint8ClampedArray(width * height * 4), width, height);
		const kernelSize = kernel.length;
		const halfKernel = Math.floor(kernelSize / 2);
		const data = output.data;
		let r, g, b, a, outputIndex, px, py, pixelIndex, weight;
		for (let y = 0; y < height; y++) {
			for (let x = 0; x < width; x++) {
				r = 0, g = 0, b = 0, a = 0;
				for (let ky = 0; ky < kernelSize; ky++) {
					for (let kx = 0; kx < kernelSize; kx++) {
						px = x + kx - halfKernel;
						py = y + ky - halfKernel;
						if (px >= 0 && py >= 0 && px < width && py < height) {
							pixelIndex = (py * width + px) * 4;
							weight = kernel[ky][kx];
							r += imageData.data[pixelIndex] * weight; pixelIndex++;
							g += imageData.data[pixelIndex] * weight; pixelIndex++;
							b += imageData.data[pixelIndex] * weight; pixelIndex++;
							a += imageData.data[pixelIndex] * weight;
						}
					}
				}
				outputIndex = (y * width + x) * 4;
				data[outputIndex] = r; outputIndex++;
				data[outputIndex] = g; outputIndex++;
				data[outputIndex] = b; outputIndex++;
				data[outputIndex] = a;
			}
		}
		return output;
	}
	function generateGaussianKernel(sigma, size) {
		const kernel = [];
		const mean = Math.floor(size / 2);
		let sum = 0, dx, dy, value;
		for (let y = 0; y < size; y++) {
			kernel[y] = [];
			for (let x = 0; x < size; x++) {
				dx = x - mean;
				dy = y - mean;
				value = (1 / (2 * Math.PI * sigma * sigma)) * Math.exp(-(dx * dx + dy * dy) / (2 * sigma * sigma));
				kernel[y][x] = value;
				sum += value;
			}
		}
		for (let y = 0; y < size; y++) {
			for (let x = 0; x < size; x++) {
				kernel[y][x] /= sum;
			}
		}
		return kernel;
	}
	function mod(x, y) {
		let result = x % y;
		return result < 0 ? result + y : result;
	}
	let customModdedEffects = [];
	function chooseEffect() {
		effectSettings.innerHTML = "";
		if (effects.value === "tint") {
			effectSettings.innerHTML = "<a>Tint Color:</a><input type=\"color\" value=\"#FF0000\" id=\"e-tintcolor\"><br><a>Tint Opacity:</a><input type=\"number\" value=\"1\" min=\"0\" max=\"1\" step=\"0.00390625\" id=\"e-tintopac\"><br><a>Tint Multiplier:</a><input type=\"number\" value=\"1\" min=\"0\" max=\"255\" step=\"1\" id=\"e-tintmult\">";
			effectParams = [document.getElementById("e-tintcolor"), document.getElementById("e-tintopac"), document.getElementById("e-tintmult")];
		} else if (effects.value === "tintblend") {
			effectSettings.innerHTML = "<a>Tint Color:</a><input type=\"color\" value=\"#FF0000\" id=\"e-tintcolor\"><br><a>Blending Percentage:</a><input type=\"number\" value=\"20\" min=\"0\" max=\"100\" step=\"1\" id=\"e-tintopac\">";
			effectParams = [document.getElementById("e-tintcolor"), document.getElementById("e-tintopac")];
		} else if (effects.value === "shift") {
			effectSettings.innerHTML = "<a>Direction (in pixels. negative = leftwards, positive = rightwards):</a><input type=\"number\" value=\"0\" id=\"e-shiftdir\"><br><a>Color Padding:</a><input type=\"color\" value=\"#000000\" id=\"e-shiftcolor\"><br><a>Color Padding Opacity:</a><input type=\"number\" value=\"0\" min=\"0\" max=\"1\" step=\"0.00390625\" id=\"e-shiftopac\"><br><a>Wrap Around Image:</a><input type=\"checkbox\" id=\"e-shiftwrap\"><br><a>(if enabled) Pixel Level (if disabled) Integral Level:</a><input type=\"checkbox\" id=\"e-shiftint\" checked>";
			effectParams = [document.getElementById("e-shiftdir"), document.getElementById("e-shiftcolor"), document.getElementById("e-shiftopac"), document.getElementById("e-shiftwrap"), document.getElementById("e-shiftint")];
		} else if (effects.value === "backg") {
			effectSettings.innerHTML = "<a>Background Color:</a><input type=\"color\" value=\"#000000\" id=\"e-backcolor\">";
			effectParams = [document.getElementById("e-backcolor")];
		} else if (effects.value === "gblur" || effects.value === "sharpg") {
			effectSettings.innerHTML = "<a>Kernel Size (Slight Blur Spread, and Smoothness):</a><input type=\"number\" value=\"3\" step=\"2\" min=\"1\" max=\"15\" id=\"e-gblurkernel\"><br><a>Sigma Value:</a><input type=\"number\" value=\"1\" step=\"0.1\" min=\"0\" max=\"100\" id=\"e-gblursigma\">";
			effectParams = [document.getElementById("e-gblurkernel"), document.getElementById("e-gblursigma")];
		} else if (effects.value === "crop" || effects.value === "rect") {
			effectSettings.innerHTML = "<a>X:</a><input type=\"number\" value=\"0\" id=\"e-cropx\"><br><a>Y:</a><input type=\"number\" value=\"0\" id=\"e-cropy\"><br><a>Width:</a><input type=\"number\" value=\"0\" id=\"e-cropw\"><br><a>Height:</a><input type=\"number\" value=\"0\" id=\"e-croph\"><br><a>" + (effects.value === "rect" ? "Rectangle" : "Highlight") + " Color:</a><input type=\"color\" value=\"#ffffff\" id=\"e-cropc\">" + (effects.value === "rect" ? "<br><a>Rectangle Opacity:</a><input type=\"number\" value=\"1\" step=\"0.01\" min=\"0\" max=\"1\" id=\"e-recto\">" : "");
			effectParams = [document.getElementById("e-cropx"), document.getElementById("e-cropy"), document.getElementById("e-cropw"), document.getElementById("e-croph"), document.getElementById("e-cropc"), document.getElementById("e-recto")];
			for (const p of effectParams) {
				p.oninput = function() {
					if (p.type !== "color") {
						if (p.id === "e-recto") p.value = String(+p.value.trim()); else p.value = String(Math.round(+p.value.trim()));
					}
					context.putImageData(currentImageData, 0, 0);
					context.fillStyle = "rgba(" + extractRGBA2(effectParams[4].value, 0.3).join(", ") + ")";
					context.fillRect(+effectParams[0].value, +effectParams[1].value, +effectParams[2].value, +effectParams[3].value);
				}
			}
		} else if (effects.value === "inv" || effects.value === "sepia" || effects.value === "graya" || effects.value === "grayb" || effects.value === "rgbsh" || effects.value === "rgbre" || effects.value === "smudge") {
			effectSettings.innerHTML = "<a>Progress (as a percentage):</a><input type=\"number\" value=\"100\" step=\"0.390625\" min=\"0\" max=\"100\" id=\"e-invpro\">%" + (effects.value === "smudge" ? "<br><a>Smudging factor (as a percentage):</a><input type=\"number\" value=\"5\" step=\"0.390625\" min=\"0\" max=\"100\" id=\"e-smudgepro\">%" : "");
			effectParams = [document.getElementById("e-invpro"), document.getElementById("e-smudgepro")];
		} else if (effects.value === "resi" || effects.value === "parag" || effects.value === "resid") {
			effectSettings.innerHTML = "<a>Width:</a><input type=\"number\" value=\"\" id=\"e-resiw\"><br><a>Height:</a><input type=\"number\" value=\"\" id=\"e-resih\">" + (effects.value === "resi" ? "<br><a>Anti-aliasing:</a><input type=\"checkbox\" checked id=\"e-resia\">" : "");
			effectParams = [document.getElementById("e-resiw"), document.getElementById("e-resih"), effects.value === "resi" ? document.getElementById("e-resia") : null];
			effectParams[0].value = canvas.width;
			effectParams[1].value = canvas.height;
		} else if (effects.value === "contr") {
			effectSettings.innerHTML = "<a>Contrast Level:</a><input type=\"number\" value=\"0.5\" step=\"0.02\" min=\"0\" max=\"10\" id=\"e-contr\">";
			effectParams = [document.getElementById("e-contr")];
		} else if (effects.value === "grayc") {
			effectSettings.innerHTML = "<a>Progress (as a percentage):</a><input type=\"number\" value=\"100\" step=\"0.390625\" min=\"0\" max=\"100\" id=\"e-graypro\">%<br><a>R Grayscale Multiplier:</a><input type=\"number\" value=\"100\" step=\"0.390625\" min=\"0\" max=\"100\" id=\"e-grayr\">%<br><a>G Grayscale Multiplier:</a><input type=\"number\" value=\"100\" step=\"0.390625\" min=\"0\" max=\"100\" id=\"e-grayg\">%<br><a>B Grayscale Multiplier:</a><input type=\"number\" value=\"100\" step=\"0.390625\" min=\"0\" max=\"100\" id=\"e-grayb\">%";
			effectParams = [document.getElementById("e-graypro"), document.getElementById("e-grayr"), document.getElementById("e-grayg"), document.getElementById("e-grayb")];
		} else if (effects.value === "opac") {
			effectSettings.innerHTML = "<a>Transparency (as a percentage):</a><input type=\"number\" value=\"0\" step=\"0.390625\" min=\"0\" max=\"100\" id=\"e-opactr\"><a id=\"percent\">%</a><br><a>Act As Opacity Multiplier:</a><input type=\"checkbox\" id=\"e-opacmu\">";
			effectParams = [document.getElementById("e-opactr"), document.getElementById("e-opacmu")];
			let x = document.getElementById("percent");
			effectParams[1].oninput = function() {
				x.textContent = effectParams[1].checked ? "x" : "%";
				effectParams[0].step = effectParams[1].checked ? "0.01" : "0.390625";
				effectParams[0].max = effectParams[1].checked ? "10" : "100";
				effectParams[0].value = effectParams[1].checked ? +effectParams[0].value / 100 : +effectParams[0].value * 100;
			}
		} else if (effects.value === "jpeg" || effects.value === "webp" || effects.value === "avif") {
			effectSettings.innerHTML = "<a>Quality:</a><input type=\"number\" value=\"80\" step=\"1\" min=\"1\" max=\"100\" id=\"e-jpegq\">";
			effectParams = [document.getElementById("e-jpegq")];
		} else if (effects.value === "minip") {
			effectSettings.innerHTML = "<a>Palette Reduction:</a><input type=\"number\" value=\"16\" step=\"1\" min=\"1\" max=\"256\" id=\"e-minipq\">";
			effectParams = [document.getElementById("e-minipq")];
		} else if (effects.value === "jpegd") {
			effectSettings.innerHTML = "<a>Effect Interval:</a><input type=\"number\" value=\"0.05\" step=\"0.01\" min=\"0\" max=\"10\" id=\"e-jpegdint\">";
			effectParams = [document.getElementById("e-jpegdint")];
		} else if (effects.value === "mp3") {
			effectSettings.innerHTML = "<a>Bitrate:</a><input type=\"number\" value=\"128\" step=\"16\" min=\"32\" max=\"320\" id=\"e-mp3bitrate\"><br><a>This effect is unconventional. First, the image data is directly encoded using <a href=\"https://github.com/webpack-contrib/lamejs\">lamejs</a> with the chosen bitrate, then the MP3 data is decoded back into the image. THIS PROCESS MAY BE COMPUTATIONALLY EXPENSIVE FOR LARGER IMAGES!</a>";
			effectParams = [document.getElementById("e-mp3bitrate")];
		} else if (effects.value === "draw") {
			effectSettings.innerHTML = "<a>Size (in pixels):</a><input type=\"number\" value=\"2\" step=\"0.5\" min=\"0.01\" max=\"4096\" id=\"e-drawwidth\"><br><a>Color:</a><input type=\"color\" value=\"#000000\" id=\"e-drawcolor\"><br><a>Sharp Edges:</a><input type=\"checkbox\" id=\"e-drawsharp\">";
			effectParams = [document.getElementById("e-drawwidth"), document.getElementById("e-drawcolor"), document.getElementById("e-drawsharp")];
		} else if (effects.value === "h264") {
			effectSettings.innerHTML = "<a>Bitrate:</a><input type=\"number\" value=\"1000\" step=\"1000\" min=\"1000\" max=\"1000000\" id=\"e-h264bitrate\"><br><a>The process of encoding a large image can be very intensive in many computers. Make sure your browser supports VideoEncoder and VideoFrame features.</a>";
			effectParams = [document.getElementById("e-h264bitrate")];
		} else {
			const x = customModdedEffects.find(x => x[0] === effects.value);
			if (x) {
				effectSettings.innerHTML = x[1];
				effectParams = x[2]();
			} else {
				effectSettings.innerHTML = "";
				effectParams = [];
			}
		}
		isDrawing = effects.value === "draw";
	}
	let isMouseDown;
	canvas.onmousedown = function(event) {
		if (isDrawing) {
			isMouseDown = true;
			const bs = canvas.getBoundingClientRect();
			lastX = event.clientX - bs.x;
			lastY = event.clientY - bs.y;
			context.beginPath();
			context.lineWidth = +effectParams[0].value;
			context.strokeStyle = effectParams[1].value;
			context.lineCap = effectParams[2].checked ? "butt" : "round";
			context.moveTo(lastX, lastY);
			context.lineTo(lastX + 0.001, lastY + 0.001);
			context.stroke();
		}
	}
	canvas.onmousemove = function(event) {
		if (isDrawing && isMouseDown) {
			const bs = canvas.getBoundingClientRect();
			context.beginPath();
			context.moveTo(lastX, lastY);
			lastX = event.clientX - bs.x;
			lastY = event.clientY - bs.y;
			context.lineTo(lastX, lastY);
			context.stroke();
		}
	}
	document.body.onmouseup = function(event) {
		if (isDrawing) {
			isMouseDown = false;
		}
	}
	effects.oninput = chooseEffect;
	apply.onclick = async function() {
		const imageData = currentImageData.data;
		let len = imageData.length;
		switch (effects.value) {
			case "tint": {
				let i = 0, tintColor = extractRGBA(effectParams[0].value, Math.max(0, Math.min(1, +effectParams[1].value)));
				tintColor = tintColor.map(x => x * +effectParams[2].value);
				if (tintColor[0] === 1 && tintColor[1] === 1 && tintColor[2] === 1) {
					if (tintColor[3] !== 1) {
						for (i = 3; i < len; i += 4) {
							imageData[i] *= tintColor[3];
						}
					}
				} else {
					for (; i < len;) {
						imageData[i] *= tintColor[0]; i++;
						imageData[i] *= tintColor[1]; i++;
						imageData[i] *= tintColor[2]; i++;
						imageData[i] *= tintColor[3]; i++;
					}
				}
				break;
			}
			case "tintblend": {
				let i = 0, tintColor = extractRGBA2(effectParams[0].value, Math.max(0, Math.min(1, +effectParams[1].value / 100)));
				if (tintColor[3] === 0) {} else if (tintColor[3] === 100) {
					for (; i < len;) {
						imageData[i] = tintColor[0]; i++;
						imageData[i] = tintColor[1]; i++;
						imageData[i] = tintColor[2]; i++;
						imageData[i] = 255; i++;
					}
				} else {
					for (; i < len;) {
						imageData[i] = interpolate(imageData[i], tintColor[0], tintColor[3]); i++;
						imageData[i] = interpolate(imageData[i], tintColor[1], tintColor[3]); i++;
						imageData[i] = interpolate(imageData[i], tintColor[2], tintColor[3]); i++;
						imageData[i] = interpolate(imageData[i], 255, tintColor[3]); i++;
					}
				}
				break;
			}
			case "shift": {
				let i = 0, shift = -Math.round(+effectParams[0].value) * (effectParams[4].checked ? 4 : 1), colorPadding = extractRGBA2(effectParams[1].value, Math.max(0, Math.min(255, +effectParams[2].value * 255)));
				if (effectParams[3].checked) {
					if (shift === 0) {} else if (shift < 0) {
						for (i = len - 1; i >= 0;) {
							imageData[i] = imageData[mod(i + shift, len)]; i--;
							imageData[i] = imageData[mod(i + shift, len)]; i--;
							imageData[i] = imageData[mod(i + shift, len)]; i--;
							imageData[i] = imageData[mod(i + shift, len)]; i--;
						}
					} else {
						for (i = 0; i < len;) {
							imageData[i] = imageData[mod(i + shift, len)]; i++;
							imageData[i] = imageData[mod(i + shift, len)]; i++;
							imageData[i] = imageData[mod(i + shift, len)]; i++;
							imageData[i] = imageData[mod(i + shift, len)]; i++;
						}
					}
				} else {
					if (shift === 0) {} else if (shift < 0) {
						for (i = len - 1; i >= 0;) {
							if (i + shift < 0) {
								i -= 4;
								continue;
							}
							imageData[i] = imageData[i + shift]; i--;
							imageData[i] = imageData[i + shift]; i--;
							imageData[i] = imageData[i + shift]; i--;
							imageData[i] = imageData[i + shift]; i--;
						}
						for (i = -shift - 1; i >= 0;) {
							imageData[i] = colorPadding[3]; i--;
							imageData[i] = colorPadding[2]; i--;
							imageData[i] = colorPadding[1]; i--;
							imageData[i] = colorPadding[0]; i--;
						}
					} else {
						for (i = 0; i < len;) {
							if (i + shift > len) {
								i += 4;
								continue;
							}
							imageData[i] = imageData[i + shift]; i++;
							imageData[i] = imageData[i + shift]; i++;
							imageData[i] = imageData[i + shift]; i++;
							imageData[i] = imageData[i + shift]; i++;
						}
						for (i = len - shift; i < len;) {
							imageData[i] = colorPadding[0]; i++;
							imageData[i] = colorPadding[1]; i++;
							imageData[i] = colorPadding[2]; i++;
							imageData[i] = colorPadding[3]; i++;
						}
					}
				}
				break;
			}
			case "backg": {
				let i = 0, bgColor = extractRGBA2(effectParams[0].value, 100);
				for (i = 0; i < len;) {
					imageData[i] = interpolate(imageData[i], bgColor[0], (255 - imageData[i + 3]) / 255); i++;
					imageData[i] = interpolate(imageData[i], bgColor[1], (255 - imageData[i + 2]) / 255); i++;
					imageData[i] = interpolate(imageData[i], bgColor[2], (255 - imageData[i + 1]) / 255); i++;
					imageData[i] = 255; i++;
				}
				break;
			}
			case "restore": {
				context.clearRect(0, 0, +canvas.width, +canvas.height);
				canvas.width = +backupImageData.width;
				canvas.height = +backupImageData.height;
				currentImageData = new ImageData(new Uint8ClampedArray(backupImageData.data), backupImageData.width, backupImageData.height);
				break;
			}
			case "gblur": {
				currentImageData = applyGaussianBlur(currentImageData, generateGaussianKernel(Math.max(0.1, Math.min(2, +effectParams[1].value)), Math.max(1, Math.min(29, Math.round(+effectParams[0].value / 2) * 2 + 1))));
				break;
			}
			case "crop": {
				const xStart = Math.max(0, Math.min(currentImageData.width, +effectParams[0].value));
				const yStart = Math.max(0, Math.min(currentImageData.height, +effectParams[1].value));
				const xEnd = Math.max(0, Math.min(currentImageData.width, +effectParams[0].value + +effectParams[2].value));
				const yEnd = Math.max(0, Math.min(currentImageData.height, +effectParams[1].value + +effectParams[3].value));
				const croppedWidth = xEnd - xStart;
				const croppedHeight = yEnd - yStart;
				const croppedData = new Uint8ClampedArray(croppedWidth * croppedHeight * 4);
				let index = 0;
				for (let y = yStart; y < yEnd; y++) {
					for (let x = xStart; x < xEnd; x++) {
						let srcIndex = (y * currentImageData.width + x) * 4;
						croppedData[index++] = currentImageData.data[srcIndex]; srcIndex++;
						croppedData[index++] = currentImageData.data[srcIndex]; srcIndex++;
						croppedData[index++] = currentImageData.data[srcIndex]; srcIndex++;
						croppedData[index++] = currentImageData.data[srcIndex]; srcIndex++;
					}
				}
				context.clearRect(0, 0, canvas.width, canvas.height);
				canvas.width = croppedWidth;
				canvas.height = croppedHeight;
				currentImageData = new ImageData(croppedData, croppedWidth, croppedHeight);
				effects.selectedIndex = 0;
				chooseEffect();
				break;
			}
			case "inv": {
				let i = 0, invert = +effectParams[0].value * 2.55;
				for (i = 0; i < len;) {
					imageData[i] = invert - imageData[i]; i++;
					imageData[i] = invert - imageData[i]; i++;
					imageData[i] = invert - imageData[i]; i += 2;
				}
				break;
			}
			case "sharpg": {
				const cur = applyGaussianBlur(currentImageData, generateGaussianKernel(Math.max(0.1, Math.min(2, +effectParams[1].value)), Math.max(1, Math.min(29, Math.round(+effectParams[0].value / 2) * 2 + 1)))).data;
				for (let i = 0; i < len;) {
					imageData[i] = (imageData[i] - cur[i]) * 2; i++;
					imageData[i] = (imageData[i] - cur[i]) * 2; i++;
					imageData[i] = (imageData[i] - cur[i]) * 2; i += 2;
				}
				break;
			}
			case "sepia": {
				let r, g, b, prog = +effectParams[0].value / 100;
				for (let i = 0; i < len;) {
					r = imageData[i]; g = imageData[i + 1]; b = imageData[i + 2];
					imageData[i] = interpolate(imageData[i], Math.min(255, (0.393 * r) + (0.769 * g) + (0.189 * b)), prog); i++;
					imageData[i] = interpolate(imageData[i], Math.min(255, (0.349 * r) + (0.686 * g) + (0.168 * b)), prog); i++;
        				imageData[i] = interpolate(imageData[i], Math.min(255, (0.272 * r) + (0.534 * g) + (0.131 * b)), prog); i += 2;
				}
				break;
			}
			case "graya": {
				let res, prog = +effectParams[0].value / 100;
				for (let i = 0; i < len;) {
					res = (imageData[i] + imageData[i + 1] + imageData[i + 2]) / 3;
					imageData[i] = interpolate(imageData[i], res, prog); i++;
					imageData[i] = interpolate(imageData[i], res, prog); i++;
        				imageData[i] = interpolate(imageData[i], res, prog); i += 2;
				}
				break;
			}
			case "resi": {
				const image = new Image();
				image.onload = function() {
					image.onload = function() {};
					context.clearRect(0, 0, +canvas.width, +canvas.height);
					canvas.width = +effectParams[0].value;
					canvas.height = +effectParams[1].value;
					context.imageSmoothingEnabled = effectParams[2].checked;
					context.drawImage(image, 0, 0, +effectParams[0].value, +effectParams[1].value);
					currentImageData = context.getImageData(0, 0, +effectParams[0].value, +effectParams[1].value);
					context.imageSmoothingEnabled = true;
					image.src = "";
				}
				image.src = canvas.toDataURL("image/png");
				break;
			}
			case "grayb": {
				let brightness, prog = +effectParams[0].value / 100;
				for (let i = 0; i < len;) {
					brightness = (0.34 * imageData[i]) + (0.5 * imageData[i + 1]) + (0.16 * imageData[i + 2]);
					imageData[i] = interpolate(imageData[i], brightness, prog); i++;
					imageData[i] = interpolate(imageData[i], brightness, prog); i++;
					imageData[i] = interpolate(imageData[i], brightness, prog); i += 2;
				}
				break;
			}
			case "contr": {
				const contr = +effectParams[0].value + 1;
				if (contr === 0) {
					for (let i = 0; i < len;) {
						imageData[i] = 0; i++;
						imageData[i] = 0; i++;
						imageData[i] = 0; i += 2;
					}
				} else {
					for (let i = 0; i < len;) {
						imageData[i] = interpolate(0, 255, Math.pow(imageData[i] / 255, contr)); i++;
						imageData[i] = interpolate(0, 255, Math.pow(imageData[i] / 255, contr)); i++;
						imageData[i] = interpolate(0, 255, Math.pow(imageData[i] / 255, contr)); i += 2;
					}
				}
				break;
			}
			case "flipy": {
				const a = new Uint8ClampedArray(imageData.length), rowSize = 4 * currentImageData.width, hei = currentImageData.height;
				let sourceRowIndex, destRowindex;
				for (let y = 0; y < hei; y++) {
					sourceRowIndex = (currentImageData.height - 1 - y) * rowSize;
					destRowIndex = y * rowSize;
					for (let x = 0; x < rowSize; x++) {
						a[destRowIndex + x] = imageData[sourceRowIndex + x];
					}
				}
				imageData.set(a);
				break;
			}
			case "flipx": {
				const newData = new Uint8ClampedArray(imageData.length), casa = currentImageData.width * 4
				let mirroredX, mirrorCache, mirrorETarg;
				for (let y = 0; y < len; y += casa) {
					for (let x = 0; x < casa; x += 4) {
						mirroredX = casa - x - 4;
						mirrorCache = y + mirroredX, mirrorTarg = y + x;
						newData[mirrorCache] = imageData[mirrorTarg]; mirrorCache++, mirrorTarg++;
						newData[mirrorCache] = imageData[mirrorTarg]; mirrorCache++, mirrorTarg++;
						newData[mirrorCache] = imageData[mirrorTarg]; mirrorCache++, mirrorTarg++;
						newData[mirrorCache] = imageData[mirrorTarg];
					}
				}
				imageData.set(newData);
				break;
			}
			case "parag": {
				canvas.width = effectParams[0].value;
				canvas.height = effectParams[1].value;
				const requiredSize = +effectParams[0].value * +effectParams[1].value * 4;
				let deeea = new Uint8ClampedArray(requiredSize);
				deeea.set(imageData.slice(0, Math.min(requiredSize, len)));
				currentImageData = new ImageData(deeea, +canvas.width, +canvas.height);
				break;
			}
			case "rgbsh": {
				let i = 0, prog = +effectParams[0].value / 100, r, g, b;
				for (i = 0; i < len;) {
					r = imageData[i];
					g = imageData[i + 1];
					b = imageData[i + 2];
					imageData[i] = interpolate(imageData[i], g, prog); i++;
					imageData[i] = interpolate(imageData[i], b, prog); i++;
					imageData[i] = interpolate(imageData[i], r, prog); i += 2;
				}
				break;
			}
			case "rgbre": {
				let i = 0, prog = +effectParams[0].value / 100, r, g, b;
				for (i = 0; i < len;) {
					r = imageData[i];
					g = imageData[i + 1];
					b = imageData[i + 2];
					imageData[i] = interpolate(imageData[i], b, prog); i++;
					imageData[i] = interpolate(imageData[i], g, prog); i++;
					imageData[i] = interpolate(imageData[i], r, prog); i += 2;
				}
				break;
			}
			case "grayc": {
				let brightness, prog = +effectParams[0].value / 100, r = +effectParams[1].value / 100, g = +effectParams[2].value / 100, b = +effectParams[3].value / 100;
				for (let i = 0; i < len;) {
					brightness = (r * imageData[i]) + (g * imageData[i + 1]) + (b * imageData[i + 2]);
					imageData[i] = interpolate(imageData[i], brightness, prog); i++;
					imageData[i] = interpolate(imageData[i], brightness, prog); i++;
					imageData[i] = interpolate(imageData[i], brightness, prog); i += 2;
				}
				break;
			}
			case "resid": {
				canvas.width = +effectParams[0].value;
				canvas.height = +effectParams[1].value;

				// Not all browsers have the same behavior of handling direct dimension changes, so we'll clear the canvas, then put the image data
				context.clearRect(0, 0, +effectParams[0].value, +effectParams[1].value);
				break;
			}
			case "opac": {
				let op = effectParams[1].checked ? +effectParams[0].value : Math.floor(255 - +effectParams[0].value * 2.55);
				if (effectParams[1].checked) {
					for (let i = 3; i < len; i += 4) {
						imageData[i] *= op;
					}
				} else {
					for (let i = 3; i < len; i += 4) {
						imageData[i] = op;
					}
				}
				break;
			}
			case "webp":
			case "jpeg": {
				const quality = Math.min(1, Math.max(0, Math.round(+effectParams[0].value) / 100));
				if (quality !== 1) {
					const image = new Image();
					image.onload = function() {
						image.onload = function() {};
						context.drawImage(image, 0, 0, +canvas.width, +canvas.height);
						currentImageData = context.getImageData(0, 0, +canvas.width, +canvas.height);
						image.src = "";
					}
					image.src = canvas.toDataURL("image/" + effects.value, quality);
				}
				break;
			}
			case "minip": {
				let op = +effectParams[0].value, i = 0;
				for (; i < len;) {
					imageData[i] = Math.round(imageData[i] / op) * op; i++;
					imageData[i] = Math.round(imageData[i] / op) * op; i++;
					imageData[i] = Math.round(imageData[i] / op) * op; i += 2;
				}
				break;
			}
			case "rect": {
				context.fillStyle = "rgba(" + extractRGBA2(effectParams[4].value, Math.max(0, Math.min(1, +effectParams[5].value))).join(", ") + ")";
				context.fillRect(+effectParams[0].value, +effectParams[1].value, +effectParams[2].value, +effectParams[3].value);
				currentImageData = context.getImageData(0, 0, +canvas.width, +canvas.height);
				context.fillStyle = "";
				break;
			}
			case "jpegd": {
				if (+effectParams[0].value < 0.4) {
					if (!confirm("THIS IMAGE EFFECT MAY CAUSE A SEIZURE FOR THOSE WITH EPILEPSY CONDITIONS FOR RAPID INTERVAL RATES. ARE YOU SURE YOU WANT TO ENABLE THIS?")) break;
				}
				if (+canvas.width > 1000 && +canvas.height > 1000) alert("The fascinating effect must require the image to be smaller than the current dimensions."); else {
					if (+effectParams[0].value < 0.05) alert("PERFORMANCE WARNING: It is not recommended to use intervals with that pausing time! Performance degradations can easily occur, and effects can sometimes overlap with each other, breaking functionality for the time of this animation (10 seconds).");
					const int = setInterval(function() {
						// 15, 16
						effects.selectedIndex = Math.random() < 0.333333 ? (15 + Math.round(Math.random())) : (Math.random() < 0.5 ? 4 : 23 + Math.round(Math.random()));
						if (effects.selectedIndex === 23 || effects.selectedIndex === 24) {
							effects.value = effects.selectedIndex === 23 ? "jpeg" : "webp";
							effectSettings.innerHTML = "<a>Quality:</a><input type=\"number\" id=\"e-jpegq\">";
							effectParams = [document.getElementById("e-jpegq")];
							effectParams[0].value = Math.round(Math.random() * 40);
						} else if (effects.selectedIndex === 4) {
							effects.value = "shift";
							effectSettings.innerHTML = "<a>Direction (in pixels. negative = leftwards, positive = rightwards):</a><input type=\"number\" value=\"0\" id=\"e-shiftdir\"><br><a>Color Padding:</a><input type=\"color\" value=\"#000000\" id=\"e-shiftcolor\"><br><a>Color Padding Opacity:</a><input type=\"number\" value=\"0\" min=\"0\" max=\"1\" step=\"0.00390625\" id=\"e-shiftopac\"><br><a>Wrap Around Image:</a><input type=\"checkbox\" id=\"e-shiftwrap\" checked><br><a>(if enabled) Pixel Level (if disabled) Integral Level:</a><input type=\"checkbox\" id=\"e-shiftint\" checked>";
							effectParams = [document.getElementById("e-shiftdir"), document.getElementById("e-shiftcolor"), document.getElementById("e-shiftopac"), document.getElementById("e-shiftwrap"), document.getElementById("e-shiftint")];
							effectParams[0].value = Math.round(4 - Math.random() * 8);
						} else chooseEffect();
						apply.click();
					}, Math.max(0, +effectParams[0].value) * 1000);
					setTimeout(function() {clearInterval(int)}, 10000);
				}
				break;
			}
			case "mp3": {
  if (typeof lamejs === "undefined") {
    const module = await fetch("lame.min.js");
    const code = await module.text();
    eval(code);
  }

  const scaleFactor = 255.99609375;
  const pcmData = new Int16Array(imageData.length);
  for (let i = 0; i < len; i++) {
    pcmData[i] = (imageData[i] - 128) * scaleFactor;
  }

  const bitrate = Math.floor(Math.max(16, Math.min(320, +effectParams[0].value)) / 16) * 16;
  let mp3Encoder = new lamejs.Mp3Encoder(1, 48000, bitrate); // mono, 48kHz, adjusted bitrate
  let mp3Data = [];
  let buffer = mp3Encoder.encodeBuffer(pcmData);
  mp3Data.push(new Uint8Array(buffer));

  const finalBuffer = mp3Encoder.flush();
  if (finalBuffer.length > 0) {
    mp3Data.push(finalBuffer);
  }

  const mp3Blob = new Blob(mp3Data, { type: "audio/mpeg" });
  const mp3ArrayBuffer = await mp3Blob.arrayBuffer();
  mp3Data = null;  // Remove the reference to the MP3 data to free memory

  let audioContext = new (window.AudioContext || window.webkitAudioContext)();
  let audioBuffer = await new Promise((resolve, reject) => {
    audioContext.decodeAudioData(mp3ArrayBuffer, resolve, reject);
  });

  let decodedPCM = audioBuffer.getChannelData(0);

  const originalHeight = currentImageData.height;
  const originalWidth = currentImageData.width;
  const totalPixels = originalWidth * originalHeight;
  const newHeight = Math.ceil(decodedPCM.length / originalWidth);
  
  const reconstructedImageData = new Uint8ClampedArray(newHeight * originalWidth * 4);
  for (let i = 0; i < decodedPCM.length; i++) {
    reconstructedImageData[i] = Math.min(255, Math.max(0, (1 + decodedPCM[i]) * 127.5));
  }

  currentImageData = new ImageData(reconstructedImageData, originalWidth, newHeight);
  canvas.height = Math.ceil(newHeight / 4);
  context.putImageData(currentImageData, 0, 0);

  currentImageData = context.getImageData(0, 0, originalWidth, canvas.height);
  break;
}
			case "rotate": {
				const width = currentImageData.width * 4, im = new ImageData(new Uint8ClampedArray(len), currentImageData.height, currentImageData.width);
				const da = im.data;
				let k = 0, j = width - 4;
				for (; j >= 0; j -= 4) {
					for (let i = 0; i < len; i += width) {
						da[k] = imageData[j + i]; k++;
						da[k] = imageData[j + i + 1]; k++;
						da[k] = imageData[j + i + 2]; k++;
						da[k] = imageData[j + i + 3]; k++;
					}
				}
				canvas.width = im.width;
				canvas.height = im.height;
				currentImageData = im;
				break;
			}
			case "smudge": {
				let i, n = currentImageData.width * 4;
				const width = currentImageData.width * 4, smudge = +effectParams[1].value / 100, prog = +effectParams[0].value / 100;
				if (smudge === 0) return;
				for (let j = 4; j < len; j = n + 4) {
					n = j + width - 4;
					for (i = j; i < n;) {
						imageData[i] = interpolate(imageData[i], interpolate(imageData[i], imageData[i - 4], smudge), prog); i++;
						imageData[i] = interpolate(imageData[i], interpolate(imageData[i], imageData[i - 4], smudge), prog); i++;
						imageData[i] = interpolate(imageData[i], interpolate(imageData[i], imageData[i - 4], smudge), prog); i++;
						imageData[i] = interpolate(imageData[i], interpolate(imageData[i], imageData[i - 4], smudge), prog); i++;
					}
				}
			}
			case "h264": {
				await encodetoH264(currentImageData, function(video) {
					const d = document.createElement("video");
					d.oncanplaythrough = function() {
						d.oncanplaythrough = function() {};
						context.drawImage(d, 0, 0, currentImageData.width, currentImageData.height);
						currentImageData = context.getImageData(0, 0, +canvas.width, +canvas.height);
						URL.revokeObjectURL(video);
						d.src = "";
					}
					d.src = video;
				}, effectParams);
			}
			default: {
				const x = customModdedEffects.find(x => x[0] === effects.value);
				if (x) {
					x[3](len, imageData, currentImageData, function(x) {
						currentImageData = x;
					});
				}
			}
		}
		if (effects.value !== "mp3") context.putImageData(currentImageData, 0, 0);
		if (effects.value === "resid") currentImageData = context.getImageData(0, 0, +canvas.width, +canvas.height);
	}
	const css = document.getElementById("css"), bg = document.getElementById("bgcolor");
	bg.oninput = function() {
		css.textContent = `button,body,select,input{background-color:${bg.value};}button,body,a,p,h1,select,option,input{color:${extractRGBA2(bg.value, 0).reduce((a, b) => a + b) > 382 ? "black" : "white"};}`;
	}
function exportTGA() {
    let header = new Uint8Array(18);
    header[2] = 2;  // Image type: uncompressed RGB
    header[12] = +canvas.width & 0xFF;
    header[13] = (+canvas.width >> 8) & 0xFF;
    header[14] = +canvas.height & 0xFF;
    header[15] = (+canvas.height >> 8) & 0xFF;
    const choice = prompt("Should the exported TGA image use the alpha channel? (yes = RGBA is used, no = RGB is used, other choice = encoder decides the color depth)");
    header[16] = choice === "yes" ? 32 : (choice === "no" ? 24 : 0);  // Pixel depth: 24 bits (RGB), 32 bits (RGBA)
    header[17] = ORIGIN_TOP_LEFT;   // Image descriptor (no alpha)
    const imgData = currentImageData.data, len = currentImageData.data.length;
    if (header[16] === 0) {
        header[16] = 24;
        for (let i = 3; i < len; i += 4) {
            if (imgData[i] !== 255) {
                header[16] = 32;
                break;
            }
        }
    }

    // Pixel data (24-bit RGB format)
    const pixelData = new Uint8Array(currentImageData.width * currentImageData.height * (header[16] / 8));
    let idx = 0, i = 0;
    if (header[16] === 24) {
        for (; i < len; i++) {
            pixelData[idx++] = imgData[i++];   // Red
            pixelData[idx++] = imgData[i++];   // Green
            pixelData[idx++] = imgData[i++];   // Blue
        }
    } else {
        for (; i < len;) {
            pixelData[i] = imgData[i]; i++;   // Red
            pixelData[i] = imgData[i]; i++;   // Green
            pixelData[i] = imgData[i]; i++;   // Blue
            pixelData[i] = imgData[i]; i++;   // Alpha
        }
    }

    // Create the TGA file as a Blob
    const blob = new Blob([header, pixelData], { type: 'image/tga' });

    // Create a download link and trigger the download
    const link = document.createElement('a');
    link.href = URL.createObjectURL(blob);
    link.download = 'exportedImage.tga';
    link.click();
    link.remove();
}

	function exportI() {
		const choice = [
			["image/png", "PNG", false, "png"], ["image/jpeg", "JPEG", true, "jpeg"], ["image/webp", "WebP", true, "webp"], ["image/bmp", "Bitmap", false, "bmp"], ["image/tga", "Targa", false, "tga"]
		];
		const index = prompt("What is the image format you want to export in? So far, we only support " + choice.map(x => x[1]).join(", ") + ". Choose by typing in their format (case-insensitive), or typing in the index (zero-based).");
		let format;
		if (isNaN(+index.trim())) {
			const e = index.toLowerCase();
			format = choice.find(x => x[1].toLowerCase() === e);
		} else {
			format = choice[+index.trim()];
		}
		if (!format) {
			alert("Neither of the formats are selected; defaulting to PNG instead.");
			format = choice[0];
		}
		if (format[3] === "tga") {
			exportTGA();
		} else {
			canvas.toBlob((blob) => {
				const link = document.createElement('a');
				link.href = URL.createObjectURL(blob);
				if (format[3] !== "png" && (blob.type === "image/png" || blob.type === "application/octet-stream" || blob.type === "")) {
					alert("Your browser does not yet support the selected image format. The browser will default to export using PNG instead");
					format = choice[0];
				}
				link.download = 'exportedImage.' + format[3];
				link.click();
				link.remove();
			}, format[0], format[2] ? +Math.min(1, Math.max(0, +prompt("What should the quality of the exported image be? (0 = worst quality, 1 = best quality, 0.8 = balanced)"))) : 0);
		}
	}
</script>
<script src="otherEffects.js"></script>
<button onclick="exportI();">Export Image</button>
</body>
</html>
